{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0374c0",
   "metadata": {},
   "source": [
    "what is the hash I got:\n",
    "sha256:b4fc2525eca2c69a59260f583c56a7557c6ccdf8deafdba6e060f94c1c59738e\n",
    "\n",
    "I did pip install uv, uv init (it initialised project hw5 automatically), then i did uv add sciket-learn, then i did cat uv, a lot of test came up as a response, I went to the part describing the scikit-learn package, and copied the first hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to write a pipeline: but we just download it for now\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "categorical = ['lead_source']\n",
    "numeric = ['number_of_courses_viewed', 'annual_income']\n",
    "\n",
    "df[categorical] = df[categorical].fillna('NA')\n",
    "df[numeric] = df[numeric].fillna(0)\n",
    "\n",
    "train_dict = df[categorical + numeric].to_dict(orient='records')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    LogisticRegression(solver='liblinear')\n",
    ")\n",
    "\n",
    "pipeline.fit(train_dict, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48f6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-11 13:40:37--  https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving github.com (github.com)... 20.217.135.5\n",
      "Connecting to github.com (github.com)|20.217.135.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin [following]\n",
      "--2025-11-11 13:40:38--  https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1300 (1.3K) [application/octet-stream]\n",
      "Saving to: ‘pipeline_v1.bin’\n",
      "\n",
      "pipeline_v1.bin     100%[===================>]   1.27K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-11-11 13:40:38 (44.3 MB/s) - ‘pipeline_v1.bin’ saved [1300/1300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/raw/refs/heads/master/cohorts/2025/05-deployment/pipeline_v1.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08514c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a script for loading the pipeline with pickle\n",
    "import pickle\n",
    "\n",
    "with open(\"pipeline_v1.bin\", \"rb\") as f:\n",
    "    pipeline = pickle.load(f)\n",
    "\n",
    "type(pipeline)\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0f769d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability of conversion: 0.534\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "# If the pipeline includes a DictVectorizer + model like earlier, then you must pass data in the same format expected during training.\n",
    "\n",
    "test_data = [{\n",
    "    \"lead_source\": \"paid_ads\",\n",
    "    \"number_of_courses_viewed\": 2,\n",
    "    \"annual_income\": 79276.0\n",
    "}]\n",
    "\n",
    "predicted_proba = pipeline.predict_proba(test_data)[0, 1]\n",
    "print(f\"Predicted probability of conversion: {predicted_proba:.3f}\")\n",
    "\n",
    "prediction = pipeline.predict(test_data)\n",
    "print(f\"Predicted class: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e414e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction probability': 0.5340417283801275}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538065e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction probability': 0.5340417283801275}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "client = {\n",
    "    \"lead_source\": \"organic_search\",\n",
    "    \"number_of_courses_viewed\": 4,\n",
    "    \"annual_income\": 80304.0\n",
    "}\n",
    "requests.post(url, json=client).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee505e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/divyakr/Documents/other/ML/DataTalks/HW5/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
